{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ceb75355-b52f-4468-8786-446cdfd305ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3f43885f-a0d5-41f3-80d5-a7d4063c206f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=6, sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d53140fa-27d8-4bef-a074-af5828a161d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data_win_prediction.csv\",sep=\";\")\n",
    "df = df.drop(columns=[\"map\",\"\\tMatch ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "add79c04-dc77-4a60-8915-02f648a7d08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Team_A_avg_win_percentage = df.Team_A_avg_win_percentage.str.replace(\",\",\".\").astype(float)\n",
    "df.Team_B_avg_win_percentage = df.Team_B_avg_win_percentage.str.replace(\",\",\".\").astype(float)\n",
    "df.Team_A_avg_KR = df.Team_A_avg_KR.str.replace(\",\",\".\").astype(float)\n",
    "df.Team_A_avg_elo = df.Team_A_avg_elo.str.replace(\",\",\".\").astype(float)\n",
    "df.Team_B_avg_KR = df.Team_B_avg_KR.str.replace(\",\",\".\").astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1d38408b-b3d0-42ce-b5d0-3a011dd6614c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.win = df.win.map({\"team a\":0, \"team b\":1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d132732f-623f-4189-900f-5fca19a45030",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.drop(columns=[\"win\"]), df.win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "aaa72c40-4ea6-432d-b3e5-3bce10d21e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = X.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f832086a-fe13-42c1-a01f-bf7107ad52b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f2bbe51d-069f-4a33-9743-d8c8b08842c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(pd.DataFrame(X_scaled, columns=columns), y, test_size = 0.25)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "388c4452-a194-4894-a514-66cead86eaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating tensors\n",
    "X_train_tensor = torch.tensor(X_train.to_numpy(), dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test.to_numpy(), dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.to_numpy(), dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.to_numpy(), dtype=torch.float32)\n",
    "\n",
    "# intializing data into loaders\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size = 32, shuffle = True)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "val_loader = DataLoader(test_dataset, batch_size = 32, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cff7a6-e22c-4b46-ab9c-73dbc36dbf18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a7b019fe-7845-457d-a513-06a843e5d670",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "012841b4-c503-4647-be41-e6c723565f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CS_NETWORK(nn.Module):\n",
    "    def __init__(self, input_size, layer_1_size, layer_2_size, output_size):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Linear(input_size, layer_1_size),\n",
    "            nn.BatchNorm1d(layer_1_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(layer_1_size, layer_2_size),\n",
    "            nn.BatchNorm1d(layer_2_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(layer_2_size, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "88d738da-af00-4a29-888f-3434dea37c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CS_NETWORK(len(columns), 64, 64, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "835af024-453c-4f51-8d79-15251383a8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "71b9901a-5e1a-42d1-bd66-8c9603ad2d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "aa953c04-c5c6-42fc-b58c-5d0a31328d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, train_loader, epochs, threshold = 0.5) -> None:\n",
    "    model.train()\n",
    "    train_loss_list = []\n",
    "    train_acc_list = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "    \n",
    "        for x_train, y_train in train_loader:\n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x_train).squeeze()\n",
    "            loss = criterion(outputs, y_train.float())\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Accumulate loss (multiply by batch size since loss is usually mean)\n",
    "            running_loss += loss.item() * x_train.size(0)\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            predict = (outputs > 0.5).float()\n",
    "            total += y_train.size(0)\n",
    "            correct += (predict == y_train).sum().item()\n",
    "        \n",
    "        # Calculate average loss and accuracy for the epoch\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_acc = correct / total\n",
    "        \n",
    "        train_loss_list.append(epoch_loss)\n",
    "        train_acc_list.append(epoch_acc)\n",
    "    \n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch+1}/{epochs}], \",\n",
    "                f\"Loss: {epoch_loss:.4f}, \",\n",
    "                f\"Acc: {epoch_acc:.3f}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f8f2016d-0269-4dec-9b34-1f38a3d1cb6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100],  Loss: 0.4370,  Acc: 0.775\n",
      "Epoch [10/100],  Loss: 0.4306,  Acc: 0.784\n",
      "Epoch [15/100],  Loss: 0.4419,  Acc: 0.784\n",
      "Epoch [20/100],  Loss: 0.4305,  Acc: 0.783\n",
      "Epoch [25/100],  Loss: 0.4360,  Acc: 0.782\n",
      "Epoch [30/100],  Loss: 0.4385,  Acc: 0.787\n",
      "Epoch [35/100],  Loss: 0.4410,  Acc: 0.775\n",
      "Epoch [40/100],  Loss: 0.4351,  Acc: 0.789\n",
      "Epoch [45/100],  Loss: 0.4383,  Acc: 0.788\n",
      "Epoch [50/100],  Loss: 0.4381,  Acc: 0.788\n",
      "Epoch [55/100],  Loss: 0.4432,  Acc: 0.790\n",
      "Epoch [60/100],  Loss: 0.4399,  Acc: 0.778\n",
      "Epoch [65/100],  Loss: 0.4331,  Acc: 0.785\n",
      "Epoch [70/100],  Loss: 0.4356,  Acc: 0.779\n",
      "Epoch [75/100],  Loss: 0.4353,  Acc: 0.784\n",
      "Epoch [80/100],  Loss: 0.4409,  Acc: 0.781\n",
      "Epoch [85/100],  Loss: 0.4287,  Acc: 0.785\n",
      "Epoch [90/100],  Loss: 0.4324,  Acc: 0.794\n",
      "Epoch [95/100],  Loss: 0.4295,  Acc: 0.794\n",
      "Epoch [100/100],  Loss: 0.4351,  Acc: 0.791\n"
     ]
    }
   ],
   "source": [
    "train_model(model, criterion, optimizer, train_loader, epochs, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "323d9a4d-1b60-474c-bb48-f5469be6e7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_model(model, val_loader, y_test, threshold = 0.5) -> None:\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    val_accuracy_list = []\n",
    "    with torch.no_grad():\n",
    "        for x_val, y_val in val_loader:\n",
    "            x_val = x_val.to(device)\n",
    "            y_val = y_val.to(device)\n",
    "            outputs = model(x_val).squeeze()\n",
    "            predict = (outputs > threshold).float()\n",
    "\n",
    "            predict_np = predict.cpu().detach().numpy()\n",
    "            y_test_np = y_test_tensor.cpu().numpy()\n",
    "       \n",
    "            total += y_val.size(0)\n",
    "            correct += (predict == y_val).sum().item()\n",
    "\n",
    "            val_accuracy = (correct/total) * 100\n",
    "            val_accuracy_list.append(val_accuracy)\n",
    "\n",
    "            \n",
    "    print(sum(val_accuracy_list)/len(val_accuracy_list))\n",
    "    print(recall_score(predict, y_test_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "08b78614-685b-4240-a900-8ecb3a9dcdef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.53588854804369\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [15, 367]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[71], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m testing_model(model, val_loader, threshold)\n",
      "Cell \u001b[1;32mIn[70], line 21\u001b[0m, in \u001b[0;36mtesting_model\u001b[1;34m(model, val_loader, threshold)\u001b[0m\n\u001b[0;32m     17\u001b[0m         val_accuracy_list\u001b[38;5;241m.\u001b[39mappend(val_accuracy)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28msum\u001b[39m(val_accuracy_list)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(val_accuracy_list))\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28mprint\u001b[39m(recall_score(predict, y_test_tensor))\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2385\u001b[0m, in \u001b[0;36mrecall_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   2217\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m   2218\u001b[0m     {\n\u001b[0;32m   2219\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2244\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2245\u001b[0m ):\n\u001b[0;32m   2246\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the recall.\u001b[39;00m\n\u001b[0;32m   2247\u001b[0m \n\u001b[0;32m   2248\u001b[0m \u001b[38;5;124;03m    The recall is the ratio ``tp / (tp + fn)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2383\u001b[0m \u001b[38;5;124;03m    array([1. , 1. , 0.5])\u001b[39;00m\n\u001b[0;32m   2384\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2385\u001b[0m     _, r, _, _ \u001b[38;5;241m=\u001b[39m precision_recall_fscore_support(\n\u001b[0;32m   2386\u001b[0m         y_true,\n\u001b[0;32m   2387\u001b[0m         y_pred,\n\u001b[0;32m   2388\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[0;32m   2389\u001b[0m         pos_label\u001b[38;5;241m=\u001b[39mpos_label,\n\u001b[0;32m   2390\u001b[0m         average\u001b[38;5;241m=\u001b[39maverage,\n\u001b[0;32m   2391\u001b[0m         warn_for\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m\"\u001b[39m,),\n\u001b[0;32m   2392\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m   2393\u001b[0m         zero_division\u001b[38;5;241m=\u001b[39mzero_division,\n\u001b[0;32m   2394\u001b[0m     )\n\u001b[0;32m   2395\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1789\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1626\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute precision, recall, F-measure and support for each class.\u001b[39;00m\n\u001b[0;32m   1627\u001b[0m \n\u001b[0;32m   1628\u001b[0m \u001b[38;5;124;03mThe precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1786\u001b[0m \u001b[38;5;124;03m array([2, 2, 2]))\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1788\u001b[0m _check_zero_division(zero_division)\n\u001b[1;32m-> 1789\u001b[0m labels \u001b[38;5;241m=\u001b[39m _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[0;32m   1792\u001b[0m samplewise \u001b[38;5;241m=\u001b[39m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1561\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m average \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m average_options \u001b[38;5;129;01mand\u001b[39;00m average \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1559\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage has to be one of \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(average_options))\n\u001b[1;32m-> 1561\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m   1562\u001b[0m \u001b[38;5;66;03m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[39;00m\n\u001b[0;32m   1563\u001b[0m \u001b[38;5;66;03m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[0;32m   1564\u001b[0m present_labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:103\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \n\u001b[0;32m     78\u001b[0m \u001b[38;5;124;03mThis converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;124;03my_pred : array or indicator matrix\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    102\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred)\n\u001b[1;32m--> 103\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m    104\u001b[0m type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    105\u001b[0m type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    460\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [15, 367]"
     ]
    }
   ],
   "source": [
    "testing_model(model, val_loader, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b51b33-bf76-4d9e-9e5f-c2186fa864d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
